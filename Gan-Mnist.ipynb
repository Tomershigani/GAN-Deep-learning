{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apQcCMp6oI2P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import datasets \n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt \n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch; torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "from torchvision.datasets import MNIST\n",
        "from PIL import Image\n",
        "import random\n",
        "import IPython\n",
        "\n",
        "\n",
        "num_epochs = 3\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Image Preprocessing \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoVYccwK0cq0"
      },
      "outputs": [],
      "source": [
        "class ColorsA(MNIST):\n",
        "    def __init__(self, root, train=True, download=False, transform=None, target_transform=None):\n",
        "        super(ColorsA, self).__init__(root, train=train, download=download, transform=transform, target_transform=target_transform)\n",
        "        self.label_to_color_dict = {}\n",
        "        colors = [(160, 0, 160), (200, 255, 0), (0, 0, 100), (0, 255, 0), (0, 0, 255), (120, 120, 120),(0, 128, 128),(255, 165, 165), (100, 40, 40), (130, 157, 220)]\n",
        "        for i in range(10):\n",
        "          self.label_to_color_dict[i] = colors[i]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, label = self.data[index], self.targets[index]\n",
        "        img = img.numpy()\n",
        "        color = self.label_to_color_dict[label.item()]\n",
        "        img = np.stack((img, img, img), axis=2)\n",
        "        img = np.where(img > 0, color, img)\n",
        "        img = img.astype(np.uint8)\n",
        "        img = Image.fromarray(img)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "class ColorsB(MNIST):\n",
        "    def __init__(self, root, train=True, download=False, transform=None, target_transform=None):\n",
        "        super(ColorsB, self).__init__(root, train=train, download=download, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        self.label_to_color_dict = {}\n",
        "        colors = [(130, 157, 220),(100, 40, 40),(255, 165, 165),(0, 128, 128),(120, 120, 120), (0, 0, 255),(0, 255, 0), (0, 0, 100),(200, 255, 0),(160, 0, 160)]\n",
        "        for i in range(10):\n",
        "          self.label_to_color_dict[i] = colors[i]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, label = self.data[index], self.targets[index]\n",
        "        img = img.numpy()\n",
        "        color = self.label_to_color_dict[label.item()]\n",
        "        img = np.stack((img, img, img), axis=2)\n",
        "        img = np.where(img > 0, color, img)\n",
        "        img = img.astype(np.uint8)\n",
        "        img = Image.fromarray(img)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSznToGz0ppL"
      },
      "outputs": [],
      "source": [
        "def to_cuda(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return x\n",
        "\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMX9ofTFzEQe"
      },
      "outputs": [],
      "source": [
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "colored_trainA = ColorsA(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader_A = torch.utils.data.DataLoader(dataset=colored_trainA, batch_size=120, shuffle=True, num_workers = 4,pin_memory=True)\n",
        "\n",
        "colored_trainB = ColorsB(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader_B = torch.utils.data.DataLoader(dataset=colored_trainB, batch_size=120, shuffle=True, num_workers = 4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs1vuHeSyHeP"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torchvision.utils as vutils\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def generate_imgs(x, y, xy_gen, yx_gen, epoch=0):\n",
        "   \n",
        "    xy_gen.eval()\n",
        "    yx_gen.eval()\n",
        "\n",
        "    y_fake = xy_gen(x)\n",
        "    x_fake = yx_gen(y)\n",
        "\n",
        "    x_imgs = torch.zeros((x.shape[0] * 2, 3, x.shape[2], x.shape[3]))\n",
        "    y_imgs = torch.zeros((y.shape[0] * 2, 3, y.shape[2], y.shape[3]))\n",
        "\n",
        "    even_idx = torch.arange(start=0, end=x.shape[0] * 2, step=2)\n",
        "    odd_idx = torch.arange(start=1, end=x.shape[0] * 2, step=2)\n",
        "\n",
        "    x_imgs[even_idx] = x.cpu()\n",
        "    x_imgs[odd_idx] = y_fake.cpu()\n",
        "\n",
        "    y_imgs[even_idx] = y.cpu()\n",
        "    y_imgs[odd_idx] = x_fake.cpu()\n",
        "\n",
        "    rows = math.ceil((x.shape[0] * 2) ** 0.5)\n",
        "\n",
        "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,9))\n",
        "\n",
        "    x_imgs_ = torchvision.utils.make_grid(x_imgs, nrow=rows).permute(1,2,0).numpy()*255\n",
        "    x_imgs_ = x_imgs_.astype(np.uint8)\n",
        "    ax1.imshow(Image.fromarray(x_imgs_))\n",
        "    ax1.set_xticks([])\n",
        "    ax1.set_yticks([])\n",
        "\n",
        "\n",
        "    y_imgs_ = torchvision.utils.make_grid(y_imgs, nrow=rows).permute(1,2,0).numpy()*255\n",
        "    y_imgs_ = y_imgs_.astype(np.uint8)\n",
        "    ax2.imshow(Image.fromarray(y_imgs_))\n",
        "    ax2.set_xticks([])\n",
        "    ax2.set_yticks([])\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FPocVYRqL4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Discriminator_A(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator_A, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.leakyrelu = nn.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, 128 * 7 * 7)\n",
        "        x = self.leakyrelu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator_B(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Discriminator_B, self).__init__()\n",
        "      \n",
        "      self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n",
        "      self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "      self.fc1 = nn.Linear(128 * 7 * 7, 256)\n",
        "      self.fc2 = nn.Linear(256, 1)     \n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "      self.leakyrelu = nn.LeakyReLU(negative_slope=0.2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, 128 * 7 * 7)\n",
        "        x = self.leakyrelu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class Generator_A(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator_A, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 3, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class  Generator_B(nn.Module):\n",
        "    def __init__(self):\n",
        "        super( Generator_B, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 3, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KAKNfHGekasd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "ab_gen = Generator_A().to(device)\n",
        "ba_gen = Generator_B().to(device)\n",
        "a_disc = Discriminator_A().to(device)\n",
        "b_disc =  Discriminator_B().to(device)\n",
        "\n",
        "# Define Optimizers\n",
        "\n",
        "dis_a_opt = optim.Adam(a_disc.parameters(), lr=0.001)\n",
        "dis_b_opt = optim.Adam(b_disc.parameters(), lr=0.001)\n",
        "gen_ab_opt = optim.Adam(ab_gen.parameters(), lr=0.001)\n",
        "gen_ba_opt = optim.Adam(ba_gen.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "a_fixed, _ = next(iter(train_loader_A))\n",
        "b_fixed, _ = next(iter(train_loader_B))\n",
        "a_fixed = a_fixed.to(device)\n",
        "b_fixed = b_fixed.to(device)\n",
        "\n",
        "\n",
        "def train(epochs):\n",
        "  for epoch in range(epochs):\n",
        "      print(f\"Epoch: {epoch+1} / {epochs}\")\n",
        "      print(\"-\"*90)\n",
        "\n",
        "      running_ab_gen_loss = 0.0\n",
        "      running_ba_gen_loss = 0.0\n",
        "      running_a_disc_loss = 0.0\n",
        "      running_b_disc_loss = 0.0\n",
        "\n",
        "      for i, (a_data, b_data) in enumerate(zip(train_loader_A, train_loader_B)):\n",
        "\n",
        "          # Loading data\n",
        "          a_real, _ = a_data\n",
        "          b_real, _ = b_data\n",
        "\n",
        "          a_real = a_real.to(device)\n",
        "          b_real = b_real.to(device)\n",
        "\n",
        "          batch_size = a_real.size(0)\n",
        "\n",
        "          real_labels = torch.ones(batch_size).to(device)\n",
        "          fake_labels = torch.zeros(batch_size).to(device)\n",
        "\n",
        "          # ======================================= Training A Discriminator =======================================\n",
        "          a_disc.train()\n",
        "          ba_gen.train(False)\n",
        "\n",
        "          ## real images\n",
        "          a_real_out = a_disc(a_real)\n",
        "          a_disc_real_loss = criterion(a_real_out.squeeze(1), real_labels)\n",
        "\n",
        "          ## fake images\n",
        "          a_fake = ba_gen(b_real)\n",
        "          a_fake_out = a_disc(a_fake)\n",
        "          a_disc_fake_loss = criterion(a_fake_out.squeeze(1), fake_labels)\n",
        "          \n",
        "          a_disc_total_loss = a_disc_real_loss + a_disc_fake_loss\n",
        "          a_disc.zero_grad()\n",
        "          running_a_disc_loss += a_disc_total_loss.item()           \n",
        "          a_disc_total_loss.backward()\n",
        "          dis_a_opt.step()\n",
        "\n",
        "          # ======================================= Training B -> A Generator =======================================\n",
        "          a_disc.train(False)\n",
        "          ba_gen.train()\n",
        "\n",
        "          a_fake = ba_gen(b_real)\n",
        "          a_fake_out = a_disc(a_fake)\n",
        "          ba_gen_loss = criterion(a_fake_out.squeeze(1), real_labels)\n",
        "          running_ba_gen_loss += ba_gen_loss.item()\n",
        "\n",
        "          a_disc.zero_grad()\n",
        "          ba_gen.zero_grad()\n",
        "          ba_gen_loss.backward()\n",
        "          gen_ba_opt.step()\n",
        "\n",
        "          ba_gen.train(False)\n",
        "          # ======================================= Training B Discriminator =======================================\n",
        "          b_disc.train()\n",
        "          ab_gen.train(False)\n",
        "\n",
        "          ## real images\n",
        "          b_real_out = b_disc(b_real)\n",
        "          b_disc_real_loss = criterion(b_real_out.squeeze(1), real_labels)\n",
        "\n",
        "          ## fake images\n",
        "          b_fake = ab_gen(a_real)\n",
        "          b_fake_out = b_disc(b_fake)\n",
        "          b_disc_fake_loss = criterion(b_fake_out.squeeze(1), fake_labels)\n",
        "\n",
        "          b_disc_total_loss = b_disc_real_loss + b_disc_fake_loss\n",
        "          b_disc.zero_grad()\n",
        "          running_b_disc_loss += b_disc_total_loss.item()           \n",
        "          b_disc_total_loss.backward()\n",
        "          dis_b_opt.step()\n",
        "\n",
        "          # ======================================= Training A -> B Generator =======================================\n",
        "          b_disc.train(False)\n",
        "          ab_gen.train()\n",
        "\n",
        "          b_fake = ab_gen(a_real)\n",
        "          b_fake_out = b_disc(b_fake)\n",
        "          ab_gen_loss = criterion(b_fake_out.squeeze(1), real_labels)\n",
        "          running_ab_gen_loss += ab_gen_loss.item()\n",
        "\n",
        "          b_disc.zero_grad()\n",
        "          ab_gen.zero_grad()\n",
        "          ab_gen_loss.backward()\n",
        "          gen_ab_opt.step()\n",
        "\n",
        "          ab_gen.train(False)\n",
        "              \n",
        "      print(f\"avg discriminator A loss: {round(running_a_disc_loss/len(train_loader_A),4)}\")\n",
        "      print(f\"avg discriminator B loss: {round(running_b_disc_loss/len(train_loader_A),4)}\")\n",
        "      print(f\"avg generator from A to B loss: {round(running_ab_gen_loss/len(train_loader_A),4)}\")\n",
        "      print(f\"avg generator from B to A loss: {round(running_ba_gen_loss/len(train_loader_A),4)}\")\n",
        "      \n",
        "      print(\"-\"*90)\n",
        "      generate_imgs(a_fixed, b_fixed, ab_gen, ba_gen)\n",
        "\n",
        "  generate_imgs(a_fixed, b_fixed, ab_gen, ba_gen)\n",
        "\n",
        "\n",
        "train(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JXI8E5kjL9N1"
      },
      "outputs": [],
      "source": [
        "torch.save(ab_gen.state_dict(), 'ab_gen.pkl')\n",
        "torch.save(ba_gen.state_dict(), 'ba_gen.pkl')\n",
        "torch.save(a_disc.state_dict(), 'a_disc.pkl')\n",
        "torch.save(b_disc.state_dict(), 'b_disc.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}